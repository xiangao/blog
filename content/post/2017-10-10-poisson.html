---
title: Which count data model to use
author: Xiang Ao
date: '2017-10-10'
slug: poisson
categories:
  - R
tags:
  - plot
  - regression
  - R
---



<div id="a-comparison-of-various-count-data-models-with-extra-zeros" class="section level1">
<h1>A comparison of various count data models with extra zeros</h1>
<p>In empirical studies, data sets with a lot of zeros are often hard to model. There are various models to deal with it: zero-inflated Poisson model, Negative Binomial (NB)model, hurdle model, etc.</p>
<p>Here we are following a zero-inflated model’s thinking: model the data with two processes. One is a Bernoulli process, the other one is a count data process (Poisson or NB).</p>
<p>We’d like to see, in this simulation exercise, how different models perform with changes of sample size and percentage of zeros (we expect the less zero, the better a plain Poisson model would perform). Therefore we vary sample size <span class="math inline">\(n\)</span> and an indicator of how much percentage of zeros in the data <span class="math inline">\(\theta\)</span>.</p>
<p>For the count data process (<span class="math inline">\(y_c\)</span>): <span class="math display">\[ log(y_c) = 2 x + u \]</span></p>
<p>For the Bernoulli process (<span class="math inline">\(y_b\)</span>):</p>
<p><span class="math display">\[ z_1 = 4 z + \theta \]</span> <span class="math display">\[ logit(y_b) = z_1 \]</span> <span class="math display">\[ p_y = \frac{e^z_1}{1+e^{z_1}} \]</span></p>
<p>Combining these two processes:</p>
<p><span class="math display">\[ y = y_c \ \text{if} \ p_y=1\]</span> <span class="math display">\[ y = y_b \ \text{if} \ p_y=0\]</span></p>
<div id="zero-inflated-poisson-models" class="section level2">
<h2>Zero-inflated Poisson models</h2>
<p>A zero-inflated Poisson needs specifying both the binary process and the count process correctly. Often than not, we don’t have a model for the binary process. Many people simply use the same explanatory variables for both processes. We simulate both situations. Case 1: suppose we observe <span class="math inline">\(z\)</span>, and case 2: suppose we don’t observe <span class="math inline">\(z\)</span>. In the graph below, they are labeled zip1 and zip2.</p>
</div>
<div id="poisson-model" class="section level2">
<h2>Poisson model</h2>
<p>A plain Poisson model returns a consistent estimator for the coefficients, with or without Poisson-distributed data. We expect Poisson model’s performance improve with sample size. Note that the standard errors from a Poisson model needs adjustment, which we do not discuss in this post.</p>
</div>
<div id="nb-model" class="section level2">
<h2>NB model</h2>
<p>NB model is used widely to handle “overdispersion” problem. That is, the variance far exceeds the mean, therefore the Poisson model is considered inappropriate. NB model addresses that by allowing an extra parameter. However, many people also use it to model “extra zero” situation, we’ll see in our simulation it may not be better than a plain Poisson model.</p>
</div>
<div id="log-linear-model" class="section level2">
<h2>Log-linear model</h2>
<p>What about an OLS model with <span class="math inline">\(log(y+1)\)</span>?</p>
</div>
<div id="hurdle-model" class="section level2">
<h2>hurdle model</h2>
<p>A hurdle model models the zero’s and other values separately; that is, the zero’s are from a binomial process only, the other positive values are from a truncated count data process. We assume here, in the simulation, we don’t observe <span class="math inline">\(z\)</span>. Therefore, <span class="math inline">\(x\)</span> is determining both binary and count processes. In the graph below, it’s labeled hurdle.</p>
<pre><code>library(MASS)
library(pscl)
library(msm)
require(snowfall)
set.seed(666)

# initialize parallel cores.
sfInit( parallel=TRUE, cpus=12)


gen.sim &lt;- function(df){
    z &lt;- rnorm(df[&#39;nobs&#39;],0,1)
    x &lt;- rnorm(df[&#39;nobs&#39;],0,1)
    u &lt;- rnorm(df[&#39;nobs&#39;],0,1)
 #generate count data
    log.mu &lt;- 2*x + u
    y.count &lt;- floor(exp(log.mu))

   # generate bernoulli data
    z1 &lt;- 4*z + df[&#39;th&#39;]
    prob &lt;- exp(z1)/(1+exp(z1))
    y.logit &lt;- rbinom(df[&#39;nobs&#39;],size=1,prob=prob)

    # zero-inflated poisson
    y &lt;- ifelse(y.logit==1, y.count,y.logit)
    m1 &lt;- zeroinfl(y ~ x | z)
    m1.x &lt;- summary(m1)$coefficients$count[&#39;x&#39;,&#39;Estimate&#39;]-2
    # zero-inflated without a z
    m4 &lt;- zeroinfl(y ~ x | x)
    m4.x &lt;- summary(m4)$coefficients$count[&#39;x&#39;,&#39;Estimate&#39;]-2

    # poisson
    m2 &lt;- glm(y ~ x, family = &quot;poisson&quot;)
    m2.x &lt;- summary(m2)$coefficients[&#39;x&#39;,&#39;Estimate&#39;]-2
    # log linear with plus 1
    y.plus1 &lt;- y +1
    m3 &lt;- lm(log(y.plus1) ~ x)
    m3.x &lt;- exp(summary(m3)$coefficients[&#39;x&#39;,&#39;Estimate&#39;])-2
    #
    #
    # negative binomial
#    m5.x &lt;- tryCatch(nb1(y ~ x), error=function(e) NA)
    m5 &lt;- glm(y ~ x, family=negative.binomial(2))
    m5.x &lt;- summary(m5)$coefficients[&#39;x&#39;,&#39;Estimate&#39;]-2
    # hurdle model
    m6 &lt;- hurdle(y ~ x)
#    m5 &lt;- glm(y ~ x, family=negative.binomial(2))
    m6.x &lt;- summary(m6)$coefficients$count[&#39;x&#39;,&#39;Estimate&#39;]-2


    return(c(zip1=m1.x, poisson=m2.x, log.linear=m3.x, zip2=m4.x, nb=m5.x, hurdle=m6.x))
}


# set parameter space
sim.grid = seq(1,100,1)
th.grid = seq(-4, 4, 2)
nobs.grid = ceiling(exp(seq(4,9,1))/100)*100

data.grid &lt;- expand.grid(nobs.grid, sim.grid, th.grid)
names(data.grid) &lt;- c(&#39;nobs&#39;, &#39;nsim&#39;,&#39;th&#39;)

# export functions to the slaves
# export data to the slaves if necessary
sfExport(list=list(&quot;gen.sim&quot;))

# export function to the slaves
sfLibrary(msm)
sfLibrary(pscl)

results &lt;- data.frame(t(sfApply(data.grid, 1, gen.sim)))

# stop the cluster
sfStop()

forshiny &lt;- cbind(data.grid, results)
# write out for use in shiny.
write.csv(forshiny, &#39;results.csv&#39;)

    </code></pre>
<p>Count data models can be used even if data is not “counts”; for example, some non-negative non-integer numbers. In fact, Poisson model is consistent even if data is not Poisson-distributed, if the model specification is correct on modeling the log of expected counts. We simulate both scenarios: Case 1, data is generated from a Poisson process. Case 2, data is generated from a Normal distribution, but we use count data models to model it. The above code is for case 2.</p>
<p>We simulate 100 times with <span class="math inline">\(\theta\)</span> ranging from -4 to 4, lower number means higher percentage of zeros; number of observations from <span class="math inline">\(e^4\)</span> to <span class="math inline">\(e^9\)</span> (roughly from 50 to 8000).</p>
<p>Since there are many simulations, we used “snowfall” library to speed things up.</p>
<p>For raw code, please visit <a href="https://github.com/xiangao/poisson">case1: poisson</a> and <a href="https://github.com/xiangao/poisson2">case2: normal</a>.</p>
<p>Here are two Shiny apps: the first one I generated data from Poisson distribution, the secone is generated from normal distribution.</p>
<iframe src="https://xiangao.shinyapps.io/poisson/" height="1000" width="600" frameborder="0">
</iframe>
<iframe src="https://xiangao.shinyapps.io/poisson/" height="1000" width="600" frameborder="0">
</iframe>
<p>In the graph, there are two vertical lines. The lighter one is the bias, the other one is MSE.</p>
<p>If we can compare the situations that data generated from Poisson process and normal process, we can see using count data models to model normal distributed data is still valid, just with bigger standard deviations. With large sample, actually Poisson model out-performs NB, and Log-linear model, without having to model the extra zeros. NB model does not do well, in general. Log-linear model is the worst. Zero-inflated Poisson with correct specification of the binary process performs the best, naturally. But that relies on correct specification of the binary process, which is not always realistic. Zero-inflated Poisson or hurdle model without correct specification of the binary process are not too bad, especially when sample size is large. These two are very close since only the difference between the two is that hurdle is modeling all zeros from binary process and all positive numbers from count data process; while zip2 is modeling some zeros (probably most) from binary process and all other values (including some zeros) from a Poisson process.</p>
</div>
</div>
