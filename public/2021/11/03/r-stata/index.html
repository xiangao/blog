<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.92.1" />


<title>When is OLS coefficient the ATE - A Hugo website</title>
<meta property="og:title" content="When is OLS coefficient the ATE - A Hugo website">



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About me</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">6 min read</span>
    

    <h1 class="article-title">When is OLS coefficient the ATE</h1>

    
    <span class="article-date">2021/11/03</span>
    

    <div class="article-content">
      
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="ols-cannot-be-ate-most-of-the-time" class="section level1">
<h1>OLS cannot be ATE (most of the time)</h1>
<p>Tymon Słoczyński has this cool paper(<a href="https://people.brandeis.edu/~tslocz/Sloczynski_paper_regression.pdf" class="uri">https://people.brandeis.edu/~tslocz/Sloczynski_paper_regression.pdf</a>) which helps me understand OLS better.</p>
<p>A common setup in empirical studies:</p>
<p><span class="math display">\[ y = \alpha + \tau d + X \beta \]</span></p>
<p><span class="math inline">\(d\)</span> is the treatment dummy, <span class="math inline">\(X\)</span> is the covariates. This model assumes homogeneous treatment effect. That is, <span class="math inline">\(\tau\)</span> is the ATE if treatment effect is homogeneous. But, if not, then <span class="math inline">\(\tau\)</span> is not ATE anymore, although most people treat it as ATE. Obviously we are assuming the usual unconfoundedness; that is, there are no other variables other than <span class="math inline">\(X\)</span> are driving both <span class="math inline">\(d\)</span> and <span class="math inline">\(y\)</span>.</p>
<p>In this paper, Słoczyński showed that <span class="math inline">\(\tau\)</span> is actually a convex combination of ATT and ATU (average treatment effect for the untreated), if treatment has heterogeneous effects. Therefore it can be close to ATE, or it can be quite different, depending on the weight on ATT and ATU. More surprisingly, he showed that the weights are inversely proportional to the proportion of treated vs untreated. The more number of treated units, the less weight is on ATT!</p>
<p>By definition,</p>
<p><span class="math display">\[ \tau_{ATE} = \rho \tau_{ATT} + (1- \rho) \tau_{ATU} \]</span></p>
<p>The main result from the paper is:</p>
<p><span class="math display">\[ \tau = (1- \rho) \tau_{ATT} + \rho \tau_{ATU} \]</span></p>
<p>where <span class="math inline">\(\rho = P(d=1)\)</span>, the proportion of treated; <span class="math inline">\(\tau_{ATT} = E(y(1)-y(0) | d=1)\)</span>, <span class="math inline">\(\tau_{ATU} = E(y(1)-y(0) | d=0)\)</span>, and <span class="math inline">\(\tau_{ATE} = E(y(1)-y(0))\)</span>.</p>
<p>From these two equations, we see that <span class="math inline">\(\tau\)</span> and <span class="math inline">\(\tau_{ATE}\)</span> are quite different, unless <span class="math inline">\(\rho=.5\)</span>. So if we have balanced data between treatment and control, it’s no problem to interpret OLS coefficient as the ATE; otherwise, they can be quite different. The more unbalanced, the more different these two are.</p>
<p>These results are based on the fact ATT, ATU and ATE can be calculated if we have the true propensity score, then we can estimate the heterogeneous effect by including the propensity score as an additional covariate. If we don’t, then we can include the estimated propensity score as an additional covariate.</p>
<p>Słoczyński has a package in R and stata “hettreatreg”.</p>
<pre class="r"><code>library(hettreatreg)
data(&quot;nswcps&quot;)

summary(lm(re78 ~ treated + age + age2 + educ + black + hispanic + married + nodegree  + re74 + re75, data = nswcps))</code></pre>
<pre><code>## 
## Call:
## lm(formula = re78 ~ treated + age + age2 + educ + black + hispanic + 
##     married + nodegree + re74 + re75, data = nswcps)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -25130  -3601   1274   3668  55040 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 7634.34415  736.67074  10.363  &lt; 2e-16 ***
## treated      793.58704  548.25433   1.447  0.14778    
## age         -233.67749   41.18067  -5.674 1.42e-08 ***
## age2           1.81437    0.56099   3.234  0.00122 ** 
## educ         166.84923   28.65984   5.822 5.94e-09 ***
## black       -790.60856  213.24523  -3.708  0.00021 ***
## hispanic    -175.97512  218.99126  -0.804  0.42166    
## married      224.26599  149.84542   1.497  0.13450    
## nodegree     311.84453  178.51743   1.747  0.08068 .  
## re74           0.29534    0.01222  24.175  &lt; 2e-16 ***
## re75           0.47064    0.01216  38.700  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7002 on 16166 degrees of freedom
## Multiple R-squared:  0.4762, Adjusted R-squared:  0.4758 
## F-statistic:  1469 on 10 and 16166 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>outcome &lt;- nswcps$re78
treated &lt;- nswcps$treated
our_vars &lt;- c(&quot;age&quot;, &quot;age2&quot;, &quot;educ&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re74&quot;, &quot;re75&quot;)
covariates &lt;- subset(nswcps, select = our_vars)

hettreatreg(outcome, treated, covariates, verbose = TRUE)</code></pre>
<pre><code>## 
## &quot;OLS&quot; is the estimated regression coefficient on treated. 
##  
##    OLS = 793.6 
##  
## P(d=1) = 0.011 
## P(d=0) = 0.989 
##  
##     w1 = 0.983 
##     w0 = 0.017 
##  delta = -0.971 
##  
##    ATE = -6751 
##    ATT = 928.4 
##    ATU = -6840 
##  
## OLS = w1*ATT + w0*ATU = 793.6 
## </code></pre>
<p>To calculate ATT, ATU and ATE under heterogeneous treatment effects, this paper does it in three steps. First, estimate the propensity score equation, basically</p>
<p><span class="math display">\[ d = X \gamma \]</span></p>
<p>Second, include the predicted propensity score as a covariate and estimate the model with treatment and control group separately.</p>
<p>Third, predict the counterfactuals for the full sample. Then we get the ATE, ATT and ATU.</p>
<p>Let’s see with the same data:</p>
<pre class="r"><code>m_propensity &lt;- lm(treated ~ age + age2 + educ + black + hispanic + married + nodegree  + re74 + re75, data=nswcps)
ps &lt;- predict(m_propensity)
df_combined &lt;- data.frame(nswcps, ps)
df.1 &lt;- df_combined[which(treated == 1),]
df.0 &lt;- df_combined[which(treated == 0),]
m_ot &lt;- lm(re78 ~ ps, data = df.1)
ot &lt;- suppressWarnings(predict(m_ot, newdata = df_combined)) # add newdata option to predict for full sample

m_oc &lt;- lm(re78 ~ ps, data = df.0)
oc &lt;- suppressWarnings(predict(m_oc, newdata = df_combined)) # add newdata option to predict for full sample

te &lt;- ot - oc
ate &lt;- mean(te)
df_combined$te &lt;- te
att &lt;- as.numeric(mean(df_combined[which(treated == 1),&#39;te&#39;]))
atu &lt;- as.numeric(mean(df_combined[which(treated == 0),&#39;te&#39;]))

print(paste(&quot;ate=&quot;, signif(ate, 4)))</code></pre>
<pre><code>## [1] &quot;ate= -6751&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;att=&quot;, signif(att, 4)))</code></pre>
<pre><code>## [1] &quot;att= 928.4&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;atu=&quot;, signif(atu, 4)))</code></pre>
<pre><code>## [1] &quot;atu= -6840&quot;</code></pre>
<p>We see in this case OLS coefficient is hugely different from ATE. This is because <span class="math inline">\(P(d=1)\)</span> is only .01, about 1 percent; we have much larger control group than treatment group. In this case, the OLS coefficient is far different from ATE; in fact, it’s pretty close to ATT.</p>
<p>Now, what’s the intuition that OLS coefficient is just the opposite as the ATE in terms of weighting ATT and ATU? The reason is that OLS is to predict actual outcome, not counterfactual outcome. For calculating ATE, we need counterfactual outcome predicted. Now suppose we have a lot of control observations, we’d much better predicting <span class="math inline">\((y(0)| d==0)\)</span> rather than <span class="math inline">\((y(1) | d==1)\)</span>. That is, we are better getting the slope of <span class="math inline">\((y(0) | d==0, X=x)\)</span>; therefore predicting <span class="math inline">\((y(0) | d==1, X=x)\)</span>. Therefore although treatment group has less observations, but because the <span class="math inline">\((y(0) | d==1)\)</span> is better predicted, the ATT is better estimated, thus more weight. If the opposite happens, then the ATU should be more heavily weighted. Thus the counter-intuitive weighting.</p>
</div>
<div id="regression-adjustment" class="section level1">
<h1>Regression adjustment</h1>
<p>Słoczyński’s method is to include propensity score as a covariate. This propensity score serves as a proxy as all covariates. As Rubin and Rosenbaum showed, propensity score is sufficient statistic for all covariates. Another way to allow treatment effect to differ across all covariates is to allow interaction of treatment dummy with all covariates, then I am doing “Regression Adjustment” (see stata’s “treatreg RA”). We can calcuate ATE, ATT, ATU after the linear model.</p>
<pre class="r"><code>library(tidyverse)</code></pre>
<pre><code>## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──</code></pre>
<pre><code>## ✓ ggplot2 3.3.5     ✓ purrr   0.3.4
## ✓ tibble  3.1.6     ✓ dplyr   1.0.7
## ✓ tidyr   1.1.4     ✓ stringr 1.4.0
## ✓ readr   2.1.1     ✓ forcats 0.5.1</code></pre>
<pre><code>## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code>lm1 &lt;- lm(re78 ~ treated*(age + age2 +  educ + black + hispanic + married + nodegree  + re74 + re75), data = nswcps)
y1 &lt;- predict(lm1,newdata=nswcps %&gt;% mutate(treated=1))
y0 &lt;- predict(lm1,newdata=nswcps %&gt;% mutate(treated=0))
ate=mean(y1-y0) #ate
print(paste(&quot;ate=&quot;,  signif(ate, 4)))</code></pre>
<pre><code>## [1] &quot;ate= -4930&quot;</code></pre>
<pre class="r"><code>y1.att &lt;- predict(lm1,newdata=nswcps %&gt;% filter(treated==1))
y0.att &lt;- predict(lm1,newdata=nswcps %&gt;% filter(treated==1) %&gt;% mutate(treated=0))
att=mean(y1.att)-mean(y0.att) #att
print(paste(&#39;att=&#39;,  signif(att, 4)))</code></pre>
<pre><code>## [1] &quot;att= 796&quot;</code></pre>
<pre class="r"><code>y1.atu &lt;- predict(lm1,newdata=nswcps %&gt;% filter(treated==0) %&gt;% mutate(treated=1))
y0.atu &lt;- predict(lm1,newdata=nswcps %&gt;% filter(treated==0))
atu=mean(y1.atu)-mean(y0.atu) #atu
print(paste(&#39;atu=&#39;, signif(atu, 4)))</code></pre>
<pre><code>## [1] &quot;atu= -4996&quot;</code></pre>
<p>We see this is somewhat different from Słoczyński’s method. But the point is the original OLS coefficient 794 is nowhere close to ATE. In this case, it’s very close to ATT, as the treatment group is very small.</p>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-106731399-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
  </body>
</html>

