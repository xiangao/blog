<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on A Hugo website</title>
    <link>/tags/r/</link>
    <description>Recent content in R on A Hugo website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Wed, 06 Apr 2022 00:00:00 +0000</lastBuildDate><atom:link href="/tags/r/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Chow test and more</title>
      <link>/2022/04/06/chow/</link>
      <pubDate>Wed, 06 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>/2022/04/06/chow/</guid>
      <description>Chow test Comparing coefficients across regressions is common. Chow test is one of them. If you’d like to compare coefficients of regressions for two subsets, that’s the original Chow test.
The idea is to interact the subset indicator with all the covariates or only the covariate you are interested (treatment). If you only interact the dummy with the treatment variable, then you are assuming all other covariates have the same effect across the two subsets.</description>
    </item>
    
    <item>
      <title>Recent causal inference tools</title>
      <link>/2022/01/20/npcausal/</link>
      <pubDate>Thu, 20 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>/2022/01/20/npcausal/</guid>
      <description>In this post, I’ll use simulated data to see how a few recently developed causal inference packages work.
In other posts, I have discussed some methods involving machine learning, such as TMLE, or causal forest. This time we’ll talk about nonparametric methods and double machine learning.
Identification First suppose we have a “target” parameter in mind, which is some function of the some unknown distribution \(P^*\), called a functional, say \(\psi^*(P^*)\).</description>
    </item>
    
    <item>
      <title>Fixed or Random Effect, or Both?</title>
      <link>/2019/05/23/fixed-effect-random-effect/</link>
      <pubDate>Thu, 23 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/23/fixed-effect-random-effect/</guid>
      <description>Panel data When we have a panel data (repeated observations over time, or observations clustered at higher level), we usually think of two choices: random effect or fixed effect? Economists usually prefers fixed effect models, since it wipes out all within unit heterogeneity. Economists do not like random effect models since it has a big assumption: the random effects need to be uncorrelated to other covariates in the model. To see this, suppose we have</description>
    </item>
    
    <item>
      <title>Premier League Soccer</title>
      <link>/2019/01/17/soccer-epl/</link>
      <pubDate>Thu, 17 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/17/soccer-epl/</guid>
      <description>Do you have to win head-to-head matches against top contenders to win a championship? Recently Manchester City beat Liverpool 2-1 on Jan 3. I was pleased. My favorite team is Arsenal in English Premier League (EPL), City is the second favorite. My friend, who is a Liverpool fan, argued that championship was never decided by the head-to-head matches between title contenders. I was like, “Really?”. If a team wins consistently over weaker teams, theoretically they could win the title, even if they lost most of their head-to-head games against other top contenders.</description>
    </item>
    
    <item>
      <title>Interaction term in a non-linear model</title>
      <link>/2017/12/07/interaction-term-in-a-non-linear-model/</link>
      <pubDate>Thu, 07 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/12/07/interaction-term-in-a-non-linear-model/</guid>
      <description>Interaction term in a non-linear model In a non-linear model (for example, logit or poisson model), the interpretation of the coefficient on the interaction term is tricky. Ai and Norton (2003) points out that the interaction term coefficient is not the same as people can interpret as in a linear model; that is, how much effect of \(x1\) changes with the value of \(x2\). They interpret this as a cross</description>
    </item>
    
    <item>
      <title>Interpreting interaction in a regression model</title>
      <link>/2017/12/07/interpreting-interaction/</link>
      <pubDate>Thu, 07 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/12/07/interpreting-interaction/</guid>
      <description>Interaction with two binary variables In a regression model with interaction term, people tend to pay attention to only the coefficient of the interaction term.
Let’s start with the simpliest situation: \(x_1\) and \(x_2\) are binary and coded 0/1.
\[ E(y) = \beta_1 x_1 + \beta_2 x_2 + \beta_{12} x_1x_2 \]
In this case, we have a saturated model; that is, we have three coefficients representing additive effects from the baseline situation (both \(x_1\) and \(x_2\) being 0).</description>
    </item>
    
    <item>
      <title>What model to use for rare events</title>
      <link>/2017/10/26/rare-event/</link>
      <pubDate>Thu, 26 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/10/26/rare-event/</guid>
      <description>Introducation In empirical studies, people are worried about rare event situation. That is, when you have, for example, lots of 0’s and only a few 1’s, or vice versa. Do you run a logit model, or do you use a “rare event logit”? When should you use either approach? Or there is a third approach?
Paul Allison said in his blog (https://statisticalhorizons.com/logistic-regression-for-rare-events):
“Prompted by a 2001 article by King and Zeng, many researchers worry about whether they can legitimately use conventional logistic regression for data in which events are rare.</description>
    </item>
    
    <item>
      <title>Causal Forest in panel data </title>
      <link>/2017/10/23/causal-forest-in-panel-data/</link>
      <pubDate>Mon, 23 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/10/23/causal-forest-in-panel-data/</guid>
      <description>Introduction In this simulation exercise, we use Causal Forest (Now is implemented in Generalized Random Forest) (https://github.com/swager/grf) to calculated conditional average treatment effect (or heterogenous treatment effect). We assume three different data generating processes. The first one is a linear interaction between a variable of interest and the treatment dummy. The second one assumes a nonlinear function (a step function) of a variable of interest, say \(X\), and the treatment dummy \(W\).</description>
    </item>
    
    <item>
      <title>Which count data model to use</title>
      <link>/2017/10/10/poisson/</link>
      <pubDate>Tue, 10 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/10/10/poisson/</guid>
      <description>A comparison of various count data models with extra zeros In empirical studies, data sets with a lot of zeros are often hard to model. There are various models to deal with it: zero-inflated Poisson model, Negative Binomial (NB)model, hurdle model, etc.
Here we are following a zero-inflated model’s thinking: model the data with two processes. One is a Bernoulli process, the other one is a count data process (Poisson or NB).</description>
    </item>
    
    <item>
      <title>Using machine learning for causal effect in observational study</title>
      <link>/2017/09/21/tmle/</link>
      <pubDate>Thu, 21 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/09/21/tmle/</guid>
      <description>A simulation for an OLS model In an observational study, we need to assume we have the functional form to get causal effect estimated correctly, in addtion to the assumption of treatment being exogenous.
library(MASS) library(ggplot2) library(dplyr) ## ## Attaching package: &amp;#39;dplyr&amp;#39; ## The following object is masked from &amp;#39;package:MASS&amp;#39;: ## ## select ## The following objects are masked from &amp;#39;package:stats&amp;#39;: ## ## filter, lag ## The following objects are masked from &amp;#39;package:base&amp;#39;: ## ## intersect, setdiff, setequal, union library(tmle) ## Loading required package: SuperLearner ## Loading required package: nnls ## Super Learner ## Version: 2.</description>
    </item>
    
  </channel>
</rss>
