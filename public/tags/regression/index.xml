<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>regression on A Hugo website</title>
    <link>/tags/regression/</link>
    <description>Recent content in regression on A Hugo website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 06 Apr 2022 00:00:00 +0000</lastBuildDate><atom:link href="/tags/regression/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Chow test and more</title>
      <link>/2022/04/06/chow/</link>
      <pubDate>Wed, 06 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>/2022/04/06/chow/</guid>
      <description>Chow test Comparing coefficients across regressions is common. Chow test is one of them. If you’d like to compare coefficients of regressions for two subsets, that’s the original Chow test.
The idea is to interact the subset indicator with all the covariates or only the covariate you are interested (treatment). If you only interact the dummy with the treatment variable, then you are assuming all other covariates have the same effect across the two subsets.</description>
    </item>
    
    <item>
      <title>Recent causal inference tools</title>
      <link>/2022/01/20/npcausal/</link>
      <pubDate>Thu, 20 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>/2022/01/20/npcausal/</guid>
      <description>In this post, I’ll use simulated data to see how a few recently developed causal inference packages work.
In other posts, I have discussed some methods involving machine learning, such as TMLE, or causal forest. This time we’ll talk about nonparametric methods and double machine learning.
Identification First suppose we have a “target” parameter in mind, which is some function of the some unknown distribution \(P^*\), called a functional, say \(\psi^*(P^*)\).</description>
    </item>
    
    <item>
      <title>Causal Forest in panel data </title>
      <link>/2017/10/23/causal-forest-in-panel-data/</link>
      <pubDate>Mon, 23 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/10/23/causal-forest-in-panel-data/</guid>
      <description>Introduction In this simulation exercise, we use Causal Forest (Now is implemented in Generalized Random Forest) (https://github.com/swager/grf) to calculated conditional average treatment effect (or heterogenous treatment effect). We assume three different data generating processes. The first one is a linear interaction between a variable of interest and the treatment dummy. The second one assumes a nonlinear function (a step function) of a variable of interest, say \(X\), and the treatment dummy \(W\).</description>
    </item>
    
    <item>
      <title>Which count data model to use</title>
      <link>/2017/10/10/poisson/</link>
      <pubDate>Tue, 10 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/10/10/poisson/</guid>
      <description>A comparison of various count data models with extra zeros In empirical studies, data sets with a lot of zeros are often hard to model. There are various models to deal with it: zero-inflated Poisson model, Negative Binomial (NB)model, hurdle model, etc.
Here we are following a zero-inflated model’s thinking: model the data with two processes. One is a Bernoulli process, the other one is a count data process (Poisson or NB).</description>
    </item>
    
    <item>
      <title>Using machine learning for causal effect in observational study</title>
      <link>/2017/09/21/tmle/</link>
      <pubDate>Thu, 21 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/09/21/tmle/</guid>
      <description>A simulation for an OLS model In an observational study, we need to assume we have the functional form to get causal effect estimated correctly, in addtion to the assumption of treatment being exogenous.
library(MASS) library(ggplot2) library(dplyr) ## ## Attaching package: &amp;#39;dplyr&amp;#39; ## The following object is masked from &amp;#39;package:MASS&amp;#39;: ## ## select ## The following objects are masked from &amp;#39;package:stats&amp;#39;: ## ## filter, lag ## The following objects are masked from &amp;#39;package:base&amp;#39;: ## ## intersect, setdiff, setequal, union library(tmle) ## Loading required package: SuperLearner ## Loading required package: nnls ## Super Learner ## Version: 2.</description>
    </item>
    
  </channel>
</rss>
